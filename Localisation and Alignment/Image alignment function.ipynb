{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyODSCBzlArcUANb65+ZUuL5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"zFYtcYvaAO9Y"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import imutils\n","\n","\n","\n","\n","def align_images(image, template, maxFeatures=500, keepPercent=0.2,debug=True):\n","    # convert both the input image and template to grayscale\n","    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    templateGray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n","\n","    orb = cv2.ORB_create(maxFeatures)\n","    (kpsA, descsA) = orb.detectAndCompute(imageGray, None)\n","    (kpsB, descsB) = orb.detectAndCompute(templateGray, None)\n","    # match the features\n","    method = cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\n","    matcher = cv2.DescriptorMatcher_create(method)\n","    matches = matcher.match(descsA, descsB, None)\n","\n","    matches = sorted(matches, key=lambda x:x.distance)\n","    # keep only the top matches\n","    keep = int(len(matches) * keepPercent)\n","    matches = matches[:keep]\n","    # check to see if we should visualize the matched keypoints\n","    if debug:\n","        matchedVis = cv2.drawMatches(image, kpsA, template, kpsB, matches, None)\n","        matchedVis = imutils.resize(matchedVis, width=1000)\n","        cv2.imshow(\"Matched Keypoints\", matchedVis)\n","        cv2.waitKey(0)\n","\n","    ptsA = np.zeros((len(matches), 2), dtype=\"float\")\n","    ptsB = np.zeros((len(matches), 2), dtype=\"float\")\n","    # loop over the top matches\n","    for (i, m) in enumerate(matches):\n","        # indicate that the two keypoints in the respective images\n","        # map to each other\n","        ptsA[i] = kpsA[m.queryIdx].pt\n","        ptsB[i] = kpsB[m.trainIdx].pt\n","\n","    (H, mask) = cv2.findHomography(ptsA, ptsB, method=cv2.RANSAC)\n","    # use the homography matrix to align the images\n","    (h, w) = template.shape[:2]\n","    aligned = cv2.warpPerspective(image, H, (w, h))\n","    # return the aligned image\n","    return aligned\n","\n"]},{"cell_type":"markdown","source":["Citation: https://pyimagesearch.com/2020/08/31/image-alignment-and-registration-with-opencv/"],"metadata":{"id":"g1WmxrUZjTtX"}}]}